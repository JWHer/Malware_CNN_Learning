import xgboost as xgb
from xgboost import XGBClassifier
from xgboost import plot_importance
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, accuracy_score
import pandas as pd
import matplotlib.pyplot as plt

loadpath=r"C:\Users\hacel\OneDrive\Desktop\workspace\csv\test.csv"
predpath=r"C:\Users\hacel\OneDrive\Desktop\workspace\csv\Total.csv"

mal=pd.read_csv(loadpath)
pred=pd.read_csv(predpath)
#mal.info()
#MCH, MEM, ISZ, ENT, IMB, DOS, STB, CFF, OPT, SEC

def tryHtoi(str):
    try:
        return int(str, 16)
    except:
        print(str)
        return -1

def iszToi(str):
    if str=='32bit':
        return 32
    elif str=='64bit':
        return 64
    elif str=='0':
        return 0
    print(str)
    return -1

def tryLen(str):
    try:
        return len(str)
    except:
        return 0

mal['MCH_INT']=mal['MCH'].apply(lambda x: int(x,16))
mal['MEM_INT']=mal['MEM'].apply(lambda x: tryHtoi(x))
mal['ISZ_INT']=mal['ISZ'].apply(lambda x: iszToi(x))
mal['ENT_INT']=mal['ENT'].apply(lambda x: tryHtoi(x))
mal['IMB_INT']=mal['IMB'].apply(lambda x: tryHtoi(x))

mal['DOS_LEN']=mal['DOS'].apply(lambda x: len(x))
mal['STB_LEN']=mal['STB'].apply(lambda x: tryLen(x))
mal['CFF_LEN']=mal['CFF'].apply(lambda x: len(x))
mal['OPT_LEN']=mal['OPT'].apply(lambda x: len(x))
mal['SEC_LEN']=mal['SEC'].apply(lambda x: len(x))

mal.drop(['MCH', 'MEM', 'ISZ', 'ENT', 'IMB', 'DOS', 'STB', 'CFF', 'OPT', 'SEC'], axis='columns', inplace=True)

pred['MCH_INT']=pred['MCH'].apply(lambda x: int(x,16))
pred['MEM_INT']=pred['MEM'].apply(lambda x: tryHtoi(x))
pred['ISZ_INT']=pred['ISZ'].apply(lambda x: iszToi(x))
pred['ENT_INT']=pred['ENT'].apply(lambda x: tryHtoi(x))
pred['IMB_INT']=pred['IMB'].apply(lambda x: tryHtoi(x))

pred['DOS_LEN']=pred['DOS'].apply(lambda x: len(x))
pred['STB_LEN']=pred['STB'].apply(lambda x: tryLen(x))
pred['CFF_LEN']=pred['CFF'].apply(lambda x: len(x))
pred['OPT_LEN']=pred['OPT'].apply(lambda x: len(x))
pred['SEC_LEN']=pred['SEC'].apply(lambda x: len(x))

pred.drop(['MCH', 'MEM', 'ISZ', 'ENT', 'IMB', 'DOS', 'STB', 'CFF', 'OPT', 'SEC'], axis='columns', inplace=True)

cols=list(mal.columns)
col_x=cols[1:]
col_y=cols[0]

mal_train, mal_test=train_test_split(mal, test_size=0.2, random_state=0)
print(mal_train.shape)
print(mal_test.shape)

params = {'max_depth' : 3,
         'eta' : 0.1, 
         'objective' : 'binary:logistic',
         'eval_metric' : 'logloss',
         'early_stoppings' : 100 }
dtrain=xgb.DMatrix(data=mal_train[col_x], label=mal_train[col_y])
dtest=xgb.DMatrix(data=mal_test[col_x], label=mal_test[col_y])
wlist=[(dtrain, 'train'), (dtest, 'eval')]
model=xgb.train(params=params, dtrain=dtrain, num_boost_round=2000, evals=wlist)

#model=XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=4)
#model.fit(X=mal_train[col_x], y=mal_train[col_y], verbose=1)
#print(model)

fig, ax = plt.subplots()
plot_importance(model, ax=ax)
plt.show()

#model_pred=model.predict(xgb.DMatrix(data=mal_test[col_x], label=mal_test[col_y]))
#print(mean_squared_error(mal_test[col_y], model_pred))
#print( accuracy_score(mal_test[col_y], model_pred.round()) )

model_pred=model.predict(xgb.DMatrix(data=pred[col_x]))
preddf = pd.DataFrame(columns=['Name', 'ans']);
preddf['Name']=pred['MAL']
preddf['ans']=model_pred.round();
preddf.to_csv('ans.csv',index=False)